{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "from torch import linalg as LA\n",
    "from copy import deepcopy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hgiang/2022_coding/neural-network-1/final/data\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.path.dirname(os.path.abspath(''))\n",
    "data_dir = os.path.join(current_dir, 'final', 'data')\n",
    "print(data_dir)\n",
    "if not os.path.exists(data_dir): \n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu = (28, 28), sigma = (28, 28)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.ToTensor()\n",
    "mnist_train = datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "mnist_image = []\n",
    "mnist_target = []\n",
    "for image, target in mnist_train: \n",
    "    mnist_image.append(np.asarray(image).reshape(-1))\n",
    "    mnist_target.append(target)\n",
    "\n",
    "mnist_image = np.asarray(mnist_image)\n",
    "mnist_target = np.asarray(mnist_target)\n",
    "\n",
    "# Normalize the image data\n",
    "mu = np.mean(mnist_image, axis=0).reshape(28, 28)\n",
    "sigma = np.std(mnist_image, axis=0).reshape(28, 28)\n",
    "\n",
    "print(f\"mu = {mu.shape}, sigma = {sigma.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8     9     2     3\n",
      "max(mnist_image[0]) = 1.0, min(mnist_image[0]) = 0.0\n"
     ]
    }
   ],
   "source": [
    "batch_size=4\n",
    "\n",
    "# transform = transforms.ToTensor()\n",
    "tranform = transforms.Normalize(mu, sigma, inplace=False)\n",
    "\n",
    "# Get MNIST data, normalize, divide by level \n",
    "mnist_train = datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{labels[j]:5}' for j in range(batch_size)))\n",
    "print(f\"max(mnist_image[0]) = {torch.max(images[0][0])}, min(mnist_image[0]) = {torch.min(images[0][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jab(loss, net_params):\n",
    "    J = torch.autograd.grad(loss, list(net_params), create_graph=True)\n",
    "    J = torch.cat([e.flatten() for e in J]) # flatten\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hess(jab, net_params): \n",
    "    num_param = sum(p.numel() for p in net_params)\n",
    "    # Allocate Hessian size\n",
    "    H = torch.zeros((num_param, num_param))\n",
    "    \n",
    "    for i in range(num_param):\n",
    "        result = torch.autograd.grad(jab[i], list(net.parameters()), retain_graph=True)\n",
    "        H[i] = torch.cat([r.flatten() for r in result]) # flatten\n",
    "    \n",
    "    return H "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_params(param1, param2): \n",
    "    \n",
    "    # Flatten parameters \n",
    "    p1 = torch.cat([e.flatten() for e in param1])\n",
    "    p2 = torch.cat([e.flatten() for e in param2])\n",
    "\n",
    "    p = p1 - p2 \n",
    "    return LA.vector_norm(p, ord=1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_norm(param): \n",
    "    p = torch.cat([e.flatten() for e in param])\n",
    "    return LA.vector_norm(p, ord=1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(net, criterion, dataloader): \n",
    "    loss = torch.zeros(1, device=device)\n",
    "    num_batches = len(dataloader)\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        inputs = inputs.view(-1, 784)\n",
    "        loss += criterion(net(inputs), labels)\n",
    "    \n",
    "    loss = loss/num_batches\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 = 139.29965209960938, loss1 = 2.3213980197906494, jab1 = 52.422149658203125\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m p2 \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mparameters() \n\u001b[1;32m     35\u001b[0m loss2 \u001b[39m=\u001b[39m accumulated_loss\n\u001b[0;32m---> 37\u001b[0m jab2 \u001b[39m=\u001b[39m compute_jab(loss2, net\u001b[39m.\u001b[39;49mparameters())\n\u001b[1;32m     38\u001b[0m \u001b[39m# print(f\"p2 = {calc_norm(p2)}, loss2 = {calc_norm(loss2)}, jab2 = {calc_norm(jab2)}\")\u001b[39;00m\n\u001b[1;32m     40\u001b[0m param_norm \u001b[39m=\u001b[39m norm_params(p1, p2)\n",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m, in \u001b[0;36mcompute_jab\u001b[0;34m(loss, net_params)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_jab\u001b[39m(loss, net_params):\n\u001b[0;32m----> 2\u001b[0m     J \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(loss, \u001b[39mlist\u001b[39;49m(net_params), create_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      3\u001b[0m     J \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([e\u001b[39m.\u001b[39mflatten() \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m J]) \u001b[39m# flatten\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m J\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-nn1/lib/python3.11/site-packages/torch/autograd/__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    302\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    304\u001b[0m         t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,\n\u001b[1;32m    305\u001b[0m         allow_unused, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "size = len(trainloader.dataset)\n",
    "num_batches = len(trainloader)\n",
    "\n",
    "num_epochs = 5 \n",
    "\n",
    "loss1 = compute_loss(net, criterion, trainloader)\n",
    "# Get initial parameters \n",
    "p1 = net.parameters()\n",
    "jab1 = compute_jab(loss1, net.parameters())\n",
    "print(f\"p1 = {calc_norm(p1)}, loss1 = {calc_norm(loss1)}, jab1 = {calc_norm(jab1)}\")\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    accumulated_loss = torch.zeros(1, device=device)\n",
    "    \n",
    "    # Train to update the model parameters \n",
    "    for batch, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        inputs = inputs.view(-1, 784)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = net(inputs)\n",
    "        loss = criterion(pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accumulated_loss += loss\n",
    "    \n",
    "    \n",
    "    # Finish training, get parameters \n",
    "    p2 = net.parameters() \n",
    "    loss2 = accumulated_loss\n",
    "\n",
    "    jab2 = compute_jab(loss2, net.parameters())\n",
    "    # print(f\"p2 = {calc_norm(p2)}, loss2 = {calc_norm(loss2)}, jab2 = {calc_norm(jab2)}\")\n",
    "\n",
    "    param_norm = norm_params(p1, p2)\n",
    "    loss_norm = norm_params(loss1, loss2)\n",
    "    jab_norm = norm_params(jab1, jab2)\n",
    "    \n",
    "    rho = loss_norm/param_norm\n",
    "    beta = jab_norm/param_norm\n",
    "    print(f\"rho = {rho} beta = {beta}\")\n",
    "\n",
    "    loss1 = deepcopy(loss2)\n",
    "    p1 = deepcopy(p2)\n",
    "    jab1 = deepcopy(jab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.path.dirname(os.path.abspath(''))\n",
    "model_path = os.path.join(current_dir, 'final', 'mnist_net.pth')\n",
    "torch.save(net.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0423) tensor(0.0633)\n",
      "tensor(-0.0272) tensor(0.0547)\n",
      "tensor(-0.0232) tensor(0.0731)\n",
      "tensor(-0.0428) tensor(0.1004)\n",
      "tensor(-0.0449) tensor(0.0500)\n",
      "tensor(-0.0400) tensor(0.0871)\n",
      "tensor(-0.0308) tensor(0.0491)\n",
      "tensor(-0.0318) tensor(0.0427)\n",
      "tensor(-0.0471) tensor(0.1076)\n",
      "tensor(-0.0751) tensor(0.2187)\n",
      "min_hess = tensor([-0.0423, -0.0272, -0.0232, -0.0428, -0.0449, -0.0400, -0.0308, -0.0318,\n",
      "        -0.0471, -0.0751]) max_hess = tensor([0.0633, 0.0547, 0.0731, 0.1004, 0.0500, 0.0871, 0.0491, 0.0427, 0.1076,\n",
      "        0.2187])\n"
     ]
    }
   ],
   "source": [
    "testloader = DataLoader(testset, batch_size=10000, shuffle=False, pin_memory=True)\n",
    "\n",
    "num_param = sum(p.numel() for p in net.parameters())\n",
    "''' Calculate Hessian '''\n",
    "\n",
    "min_hess = []\n",
    "max_hess = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for _ in range(10): \n",
    "    for batch, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        inputs = inputs.view(-1, 784)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        pred = net(inputs)\n",
    "        loss = criterion(pred, labels)\n",
    "\n",
    "        # Allocate Hessian size\n",
    "        H = torch.zeros((num_param, num_param))\n",
    "\n",
    "        # Calculate Jacobian w.r.t. model parameters\n",
    "        J = torch.autograd.grad(loss, list(net.parameters()), create_graph=True)\n",
    "        J = torch.cat([e.flatten() for e in J]) # flatten\n",
    "\n",
    "        # Fill in Hessian\n",
    "        for i in range(num_param):\n",
    "            result = torch.autograd.grad(J[i], list(net.parameters()), retain_graph=True)\n",
    "            H[i] = torch.cat([r.flatten() for r in result]) # flatten\n",
    "        \n",
    "        print(torch.min(H), torch.max(H))\n",
    "        min_hess.append(torch.min(H))\n",
    "        max_hess.append(torch.max(H))\n",
    "\n",
    "        break \n",
    "\n",
    "min_hess = torch.tensor(min_hess)\n",
    "max_hess = torch.tensor(max_hess)\n",
    "\n",
    "print(f\"min_hess = {min_hess} max_hess = {max_hess}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0405)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(min_hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0847)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(max_hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ff = 0.061; F0 = 1.643; Fn = 0.322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1649810366624526"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Fn - Ff)/(F0 - Ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6816, 0.3936, 0.8691],\n",
       "        [0.7012, 0.7457, 0.9011],\n",
       "        [0.2661, 0.2115, 0.2770]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess = torch.load('hessian.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.8505, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-8.7001, device='cuda:0', grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "jab = torch.load('jacobian.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m jab \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(jab)\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "jab = torch.tensor(jab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0359, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(jab[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.5386, device='cuda:0', grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(jab[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.6835, device='cuda:0', grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(jab[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
