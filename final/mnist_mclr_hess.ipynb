{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Research/neural-network/final/data\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.path.dirname(os.path.abspath(''))\n",
    "data_dir = os.path.join(current_dir, 'final', 'data')\n",
    "print(data_dir)\n",
    "if not os.path.exists(data_dir): \n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu = (28, 28), sigma = (28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "mnist_image = []\n",
    "mnist_target = []\n",
    "for image, target in mnist_train: \n",
    "    mnist_image.append(np.asarray(image).reshape(-1))\n",
    "    mnist_target.append(target)\n",
    "\n",
    "mnist_image = np.asarray(mnist_image)\n",
    "mnist_target = np.asarray(mnist_target)\n",
    "\n",
    "# Normalize the image data\n",
    "mu = np.mean(mnist_image, axis=0).reshape(28, 28)\n",
    "sigma = np.std(mnist_image, axis=0).reshape(28, 28)\n",
    "\n",
    "print(f\"mu = {mu.shape}, sigma = {sigma.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     4     7     4\n",
      "max(mnist_image[0]) = 1.0, min(mnist_image[0]) = 0.0\n"
     ]
    }
   ],
   "source": [
    "batch_size=4\n",
    "\n",
    "# transform = transforms.ToTensor()\n",
    "tranform = transforms.Normalize(mu, sigma, inplace=False)\n",
    "\n",
    "# Get MNIST data, normalize, divide by level \n",
    "mnist_train = datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{labels[j]:5}' for j in range(batch_size)))\n",
    "print(f\"max(mnist_image[0]) = {torch.max(images[0][0])}, min(mnist_image[0]) = {torch.min(images[0][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.609\n",
      "[1,  4000] loss: 1.010\n",
      "[1,  6000] loss: 0.815\n",
      "[1,  8000] loss: 0.702\n",
      "[1, 10000] loss: 0.644\n",
      "[1, 12000] loss: 0.587\n",
      "[1, 14000] loss: 0.569\n",
      "[2,  2000] loss: 0.520\n",
      "[2,  4000] loss: 0.512\n",
      "[2,  6000] loss: 0.486\n",
      "[2,  8000] loss: 0.487\n",
      "[2, 10000] loss: 0.466\n",
      "[2, 12000] loss: 0.462\n",
      "[2, 14000] loss: 0.448\n",
      "[3,  2000] loss: 0.448\n",
      "[3,  4000] loss: 0.432\n",
      "[3,  6000] loss: 0.426\n",
      "[3,  8000] loss: 0.421\n",
      "[3, 10000] loss: 0.405\n",
      "[3, 12000] loss: 0.423\n",
      "[3, 14000] loss: 0.395\n",
      "[4,  2000] loss: 0.400\n",
      "[4,  4000] loss: 0.403\n",
      "[4,  6000] loss: 0.398\n",
      "[4,  8000] loss: 0.393\n",
      "[4, 10000] loss: 0.390\n",
      "[4, 12000] loss: 0.385\n",
      "[4, 14000] loss: 0.377\n",
      "[5,  2000] loss: 0.385\n",
      "[5,  4000] loss: 0.384\n",
      "[5,  6000] loss: 0.364\n",
      "[5,  8000] loss: 0.370\n",
      "[5, 10000] loss: 0.368\n",
      "[5, 12000] loss: 0.387\n",
      "[5, 14000] loss: 0.363\n",
      "[6,  2000] loss: 0.359\n",
      "[6,  4000] loss: 0.379\n",
      "[6,  6000] loss: 0.363\n",
      "[6,  8000] loss: 0.347\n",
      "[6, 10000] loss: 0.362\n",
      "[6, 12000] loss: 0.360\n",
      "[6, 14000] loss: 0.352\n",
      "[7,  2000] loss: 0.352\n",
      "[7,  4000] loss: 0.349\n",
      "[7,  6000] loss: 0.345\n",
      "[7,  8000] loss: 0.360\n",
      "[7, 10000] loss: 0.347\n",
      "[7, 12000] loss: 0.366\n",
      "[7, 14000] loss: 0.333\n",
      "[8,  2000] loss: 0.342\n",
      "[8,  4000] loss: 0.334\n",
      "[8,  6000] loss: 0.353\n",
      "[8,  8000] loss: 0.342\n",
      "[8, 10000] loss: 0.351\n",
      "[8, 12000] loss: 0.329\n",
      "[8, 14000] loss: 0.345\n",
      "[9,  2000] loss: 0.359\n",
      "[9,  4000] loss: 0.322\n",
      "[9,  6000] loss: 0.328\n",
      "[9,  8000] loss: 0.333\n",
      "[9, 10000] loss: 0.341\n",
      "[9, 12000] loss: 0.345\n",
      "[9, 14000] loss: 0.321\n",
      "[10,  2000] loss: 0.353\n",
      "[10,  4000] loss: 0.335\n",
      "[10,  6000] loss: 0.332\n",
      "[10,  8000] loss: 0.327\n",
      "[10, 10000] loss: 0.328\n",
      "[10, 12000] loss: 0.318\n",
      "[10, 14000] loss: 0.323\n",
      "[11,  2000] loss: 0.304\n",
      "[11,  4000] loss: 0.338\n",
      "[11,  6000] loss: 0.325\n",
      "[11,  8000] loss: 0.321\n",
      "[11, 10000] loss: 0.338\n",
      "[11, 12000] loss: 0.326\n",
      "[11, 14000] loss: 0.321\n",
      "[12,  2000] loss: 0.320\n",
      "[12,  4000] loss: 0.319\n",
      "[12,  6000] loss: 0.321\n",
      "[12,  8000] loss: 0.313\n",
      "[12, 10000] loss: 0.326\n",
      "[12, 12000] loss: 0.326\n",
      "[12, 14000] loss: 0.322\n",
      "[13,  2000] loss: 0.313\n",
      "[13,  4000] loss: 0.318\n",
      "[13,  6000] loss: 0.319\n",
      "[13,  8000] loss: 0.326\n",
      "[13, 10000] loss: 0.317\n",
      "[13, 12000] loss: 0.305\n",
      "[13, 14000] loss: 0.333\n",
      "[14,  2000] loss: 0.320\n",
      "[14,  4000] loss: 0.310\n",
      "[14,  6000] loss: 0.320\n",
      "[14,  8000] loss: 0.313\n",
      "[14, 10000] loss: 0.309\n",
      "[14, 12000] loss: 0.316\n",
      "[14, 14000] loss: 0.315\n",
      "[15,  2000] loss: 0.301\n",
      "[15,  4000] loss: 0.309\n",
      "[15,  6000] loss: 0.311\n",
      "[15,  8000] loss: 0.315\n",
      "[15, 10000] loss: 0.312\n",
      "[15, 12000] loss: 0.332\n",
      "[15, 14000] loss: 0.308\n",
      "[16,  2000] loss: 0.321\n",
      "[16,  4000] loss: 0.311\n",
      "[16,  6000] loss: 0.304\n",
      "[16,  8000] loss: 0.320\n",
      "[16, 10000] loss: 0.298\n",
      "[16, 12000] loss: 0.309\n",
      "[16, 14000] loss: 0.312\n",
      "[17,  2000] loss: 0.313\n",
      "[17,  4000] loss: 0.296\n",
      "[17,  6000] loss: 0.321\n",
      "[17,  8000] loss: 0.317\n",
      "[17, 10000] loss: 0.296\n",
      "[17, 12000] loss: 0.311\n",
      "[17, 14000] loss: 0.301\n",
      "[18,  2000] loss: 0.298\n",
      "[18,  4000] loss: 0.293\n",
      "[18,  6000] loss: 0.310\n",
      "[18,  8000] loss: 0.308\n",
      "[18, 10000] loss: 0.312\n",
      "[18, 12000] loss: 0.307\n",
      "[18, 14000] loss: 0.302\n",
      "[19,  2000] loss: 0.294\n",
      "[19,  4000] loss: 0.319\n",
      "[19,  6000] loss: 0.295\n",
      "[19,  8000] loss: 0.297\n",
      "[19, 10000] loss: 0.298\n",
      "[19, 12000] loss: 0.308\n",
      "[19, 14000] loss: 0.318\n",
      "[20,  2000] loss: 0.291\n",
      "[20,  4000] loss: 0.319\n",
      "[20,  6000] loss: 0.294\n",
      "[20,  8000] loss: 0.293\n",
      "[20, 10000] loss: 0.315\n",
      "[20, 12000] loss: 0.289\n",
      "[20, 14000] loss: 0.308\n",
      "Finished Training, training time = 6.111705887317657 s\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "size = len(trainloader.dataset)\n",
    "num_batches = len(trainloader)\n",
    "\n",
    "running_losses = []\n",
    "eval_every = 2000\n",
    "num_epochs = 20 \n",
    "\n",
    "start_time_s = time.time()\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        inputs = inputs.view(-1, 784)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        pred = net(inputs)\n",
    "        loss = criterion(pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if batch % eval_every == (eval_every-1):    # print every 20 mini-batches\n",
    "            running_loss = running_loss / eval_every\n",
    "            print(f'[{epoch + 1}, {batch + 1:5d}] loss: {running_loss:.3f}')\n",
    "            running_losses.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "time_s = (time.time() - start_time_s)/num_epochs\n",
    "print('Finished Training, training time = {} s'.format(time_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0189) tensor(0.0352)\n"
     ]
    }
   ],
   "source": [
    "testloader = DataLoader(testset, batch_size=10000, shuffle=False, pin_memory=True)\n",
    "\n",
    "num_param = sum(p.numel() for p in net.parameters())\n",
    "''' Calculate Hessian '''\n",
    "\n",
    "min_hess = []\n",
    "max_hess = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for _ in range(10): \n",
    "    for batch, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        inputs = inputs.view(-1, 784)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        pred = net(inputs)\n",
    "        loss = criterion(pred, labels)\n",
    "\n",
    "        # Allocate Hessian size\n",
    "        H = torch.zeros((num_param, num_param))\n",
    "\n",
    "        # Calculate Jacobian w.r.t. model parameters\n",
    "        J = torch.autograd.grad(loss, list(net.parameters()), create_graph=True)\n",
    "        J = torch.cat([e.flatten() for e in J]) # flatten\n",
    "\n",
    "        # Fill in Hessian\n",
    "        for i in range(num_param):\n",
    "            result = torch.autograd.grad(J[i], list(net.parameters()), retain_graph=True)\n",
    "            H[i] = torch.cat([r.flatten() for r in result]) # flatten\n",
    "        \n",
    "        print(torch.min(H), torch.max(H))\n",
    "\n",
    "        break \n",
    "\n",
    "# print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3938758281.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[62], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    tensor(-0.0122) tensor(0.0323)\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tensor(-0.0122) tensor(0.0323)\n",
    "tensor(-0.0545) tensor(0.0583)\n",
    "tensor(-0.0265) tensor(0.0730)\n",
    "tensor(-0.0485) tensor(0.0937)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.064325"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = 0.0323 + 0.0583 + 0.0730 + 0.0937\n",
    "avg = avg / 4\n",
    "\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testloader = DataLoader(testset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "images.size()\n",
    "image = images[0][0]\n",
    "image.size()\n",
    "\n",
    "torch.min(image)\n",
    "torch.max(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
